# Paperspace Deployment Checklist

## Pre-Deployment Validation âœ“

### 1. Code Validation
- [x] All imports tested and working
- [x] Model v1 creates and trains successfully
- [x] Model v2 creates and trains successfully (with Keras warnings that don't affect functionality)
- [x] Data loading pipeline validated
- [x] Modification generation working
- [x] Mixed dataset creation tested

### 2. Safeguards Implemented
- [x] Automatic path detection for Paperspace environments
- [x] Persistent storage to `/storage/` directory
- [x] Checkpoint saving after every epoch
- [x] Emergency saves on errors
- [x] Results saved in multiple formats (JSON, pickle)
- [x] Immediate saves after each stage

### 3. Experiments Ready
1. **v1_standard**: Original model with standard progressive training
2. **v1_mixed**: Original model with mixed training (gradual modification introduction)
3. **v2_standard**: Improved model (with gating) with standard training
4. **v2_mixed**: Improved model with mixed training

### 4. Expected Outcomes
- **v1_standard**: Should show catastrophic interference (8x loss increase)
- **v1_mixed**: Should show reduced interference
- **v2_standard**: May show some improvement due to gating
- **v2_mixed**: Best expected performance - gating + mixed training

## Deployment Commands

### 1. Upload to Paperspace
```bash
# From local machine
cd experiments/02_compositional_language
zip -r compositional_experiments.zip *.py models*.py train*.py scan*.py modification*.py
# Upload via Paperspace interface
```

### 2. On Paperspace
```bash
# Extract files
cd /notebooks/neural_networks_research/experiments/02_compositional_language
unzip compositional_experiments.zip

# Run comprehensive experiments
python paperspace_comprehensive_experiments.py

# Monitor progress
tail -f comprehensive_results_*/results.json
```

### 3. Emergency Recovery
If the instance shuts down:
```bash
# Check persistent storage
ls /storage/compositional_comprehensive_*/

# Copy results back
cp -r /storage/compositional_comprehensive_* ./

# View results
cat comprehensive_results_*/final_results.json
```

## Resource Requirements
- **GPU**: A4000 or similar (16GB+ VRAM)
- **Time**: ~2-3 hours for all 4 experiments
- **Storage**: ~2GB for checkpoints and results

## Monitoring
1. Watch GPU memory in first few minutes
2. Check that checkpoints are saving to `/storage/`
3. Verify loss/accuracy are reasonable after Stage 1
4. Monitor for out-of-memory errors

## Post-Deployment Analysis
1. Download `comprehensive_results_*/final_results.json`
2. Compare degradation percentages across experiments
3. Plot training curves for each configuration
4. Analyze gate activations in v2 models
5. Write up findings comparing all approaches

## Success Criteria
- At least one configuration shows <5% degradation from Stage 1 to Stage 4
- v2 models outperform v1 models
- Mixed training outperforms standard training
- Clear evidence that gating helps with selective modification
